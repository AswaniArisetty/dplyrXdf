---
title: "Introducing the dplyrXdf package"
author: "Hong Ooi"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Introducing dplyrXdf}
  \usepackage[utf8]{inputenc}
---

```{r, echo = FALSE, message = FALSE}
knitr::opts_chunk$set(collapse=TRUE, comment="#>")
options(dplyr.print_min=5L, dplyr.print_max=5L)

rxSetComputeContext("local")
```
## Introduction

The [dplyr package](https://cran.r-project.org/web/packages/dplyr/index.html) is a popular toolkit for data transformation and manipulation. Since its release dplyr has become very popular in the R community, for the way in which it streamlines and simplifies many common data manipulation tasks. 

Out of the box, dplyr supports data frames, data tables (from the data.table package), and a number of SQL databases including MySQL/MariaDB, SQLite, and PostgreSQL. However, a feature of dplyr is that it's _extensible_: by writing a specific backend, you can make it work with many other kinds of data sources. For example the [RSQLServer package](https://cran.r-project.org/package=RSQLServer) implements a dplyr backend for Microsoft SQL Server.

The dplyrXdf package implements such a backend for [Microsoft R Server](https://www.microsoft.com/en-au/cloud-platform/r-server) (MRS). A key feature of MRS is that it allows you to break R's memory barrier. Instead of storing data in memory as data frames, it is stored on disk, in a file format identifiable by the `.xdf` extension. The data is then processed in chunks, so that you only need enough memory to store each chunk. This allows you to work with datasets of potentially unlimited size.

MRS includes a suite of data transformation and modelling functions in the RevoScaleR package that can handle Xdf files. These functions are highly optimised and efficient, but their user interface can be complex. dplyrXdf allows you to work with Xdf files within the framework supplied by dplyr, which reduces the learning curve and allows you to become productive more quickly.

_Note that dplyrXdf is a shell on top of the existing functions provided by Microsoft R Server, which is a commercial distribution of R. You must have MRS installed to make use of dplyrXdf. In particular, Microsoft R Open does not include support for Xdf files._

## A sample dplyrXdf pipeline

For this example I'll use the flights dataset from the nycflights13 package. This is one of the datasets used in the [dplyr vignettes](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html), and crops up in many other places besides.

```{r}
library(dplyrXdf)  # also loads dplyr
library(nycflights13)

# write the data as an xdf file
flightsXdf <- rxDataStep(flights, "flights.xdf", overwrite=TRUE)
```

Consider a simple task: get the average delay and total distance covered (in kilometers) in the first half of 2013, by carrier, sorted by descending delay. This isn't very complicated, conceptually speaking: we want to do a row selection, then some basic transformations, followed by a summary, and then order the output by one of the columns.

This translates into the following sequence of RevoScaleR function calls:

```{r}
# select the rows
flights_rx1 <- rxDataStep(flightsXdf, outFile="flights_rx1.xdf",
                          rowSelection=month <= 6 & year == 2013,
                          overwrite=TRUE)

# variable transformations
flights_rx2 <- rxDataStep(flights_rx1, outFile="flights_rx2.xdf",
                          transforms=list(dist_km=distance*1.6093,
                                          delay=(arr_delay + dep_delay)/2),
                          overwrite=TRUE)

# convert carrier into a factor variable (or rxSummary will complain)
flights_rx3 <- rxFactors(flights_rx2, factorInfo="carrier",
                         outFile="flights_rx3.xdf", overwrite=TRUE)

# use rxSummary to get the summary table(s) (could also use rxCube twice)
flights_rx4 <- rxSummary(~delay:carrier + dist_km:carrier, data=flights_rx3,
                         summaryStats=c("mean", "sum"))

# extract the desired tables from the rxSummary output
flights_rx4_1 <- flights_rx4$categorical[[1]][c("carrier", "Means")]
names(flights_rx4_1)[2] <- "mean_delay"

flights_rx4_2 <- flights_rx4$categorical[[2]][c("carrier", "Sum")]
names(flights_rx4_2)[2] <- "sum_dist"

# merge the tables together
flights_rx5 <- merge(flights_rx4_1, flights_rx4_2, by="carrier", all=TRUE)

# sort the results
flights_rx5 <- flights_rx5[order(flights_rx5$mean_delay, decreasing=TRUE), ]

head(flights_rx5)
```

The equivalent in dplyrXdf would be the following pipeline:

```{r}
flightsSmry <- flightsXdf %>%
    filter(month <= 6, year == 2013) %>%
    mutate(dist_km=distance*1.6093, delay=(arr_delay + dep_delay)/2) %>%
    group_by(carrier) %>%
    summarise(mean_delay=mean(delay), sum_dist=sum(dist_km)) %>%
    arrange(desc(mean_delay))

head(flightsSmry)
```

Even with this relatively straightforward example, dplyrXdf hides the complexity of calling RevoScaleR functions while retaining their power. In particular, note the following:

* The base RevoScaleR functions require you to specify the location for the output xdf file. It's very common to end up with many different versions of your data scattered around the filesystem, causing reproducibility problems and making it hard to keep track of changes. By contrast, the dplyrXdf pipeline has no filenames. This is because dplyrXdf handles the task of file management, so that you can focus on the data itself.

* The `summarise` verb is much simpler to work with than the RevoScaleR `rxSummary` function. It doesn't require scanning through a list of output objects to find the information you're after, and it accepts grouping variables of any type (numeric, character or factor). (The alternative summarisation tool, `rxCube`, is simpler but has its own limitations: for example, it supports a much narrower range of summary statistics, and can only compute one type of statistic at a time.)

* The pipeline operator, along with the design of the verbs, makes it clear at a glance what is the sequence of operations being carried out. This is one of the major benefits of dplyr, and can now also be used with Xdf files.

Here are a couple of additional features that may not be immediately apparent from the code above:

* The verbs in dplyrXdf all read from xdf files and write to xdf files. This preserves the ability to handle large datasets without running out of memory.

* The source xdf file to a dplyrXdf pipeline is _never modified_. This provides a measure of security, so that even if there are bugs in your code, your original data is safe.


## Basic functionality

### Single-table verbs

dplyrXdf supports all the basic dplyr single-table verbs: 

* `filter` and `select` to choose rows and columns
* `mutate` and `transmute` to do data transformation
* `group_by` to define groups
* `summarise` and `do` to carry out computations on grouped data
* `arrange` to sort by variables
* `rename` to rename columns
* `distinct` to drop duplicates

Under the hood, they work by translating your pipeline into calls to the base RevoScaleR functions for working with xdf files: for example, `mutate` calls `rxDataStep` to compute transformations; `arrange` calls `rxSort`, and so on.

These verbs work exactly as they do in dplyr. Thus if you know how to use dplyr, then you also know how to use the bulk of dplyrXdf.


### Two-table verbs

dplyrXdf supports all the table-join verbs from dplyr, except for the set operations `intersect`, `setdiff` and `setequal`:

* `left_join`, `right_join`, `inner_join` and `full_join`
* `anti_join` and `semi_join`
* `union` and `union_all`

The syntax is again the same as for the dplyr versions, including joining on non-matching column names. The underlying implementation uses `rxMerge` with the appropriate arguments for each type of join.

For example, one of the joins in the [dplyr two-table verbs vignette](https://cran.r-project.org/web/packages/dplyr/vignettes/two-table.html) joins the flights table with the airports table, using the columns `dest` (in flights) and `faa` (in airports). The same code in dplyr also works in dplyrXdf:

```{r}
airportsXdf <- rxDataStep(airports, "airports.xdf", overwrite=TRUE)
flightsJoin <- left_join(
    flightsXdf %>% select(year:day, hour, origin, dest, tailnum, carrier),
    airportsXdf,
    by=c("dest"="faa"))
head(flightsJoin)
```

### Utility functions

In addition to the above verbs, dplyrXdf provides a number of functions to ease working with Xdf data sources, both in the native filesystem and in HDFS.

#### Xdf utilities

* `cbind` and `rbind` combine Xdf files
* `as.data.frame` converts an Xdf file into a data frame
* `[[`, `$` and `pull` extract a column into memory
* `sample_frac` and `sample_n` do random sampling
* `copy_xdf`, `move_xdf`, `rename_xdf` and `delete_xdf` copy, move, rename and delete an Xdf file
* `is_xdf` and `is_composite_xdf` return whether an object is a (composite) Xdf
* `as_xdf` imports a data source or data frame into an Xdf file, optionally as composite; `as_composite_xdf` and `as_standard_xdf` are shortcuts for creating a composite and standard Xdf file respectively

#### HDFS utilities

* `copy_to` uploads a dataset to HDFS, saving it as Xdf
* `collect` and `compute` do the opposite, downloading an Xdf file from HDFS
* `hdfs_upload` and `hdfs_download` transfer arbitrary files to and from HDFS
* `hdfs_dir` lists files in a HDFS directory
* `hdfs_dir_exists` and `hdfs_file_exists` test for directory/file existence
* `hdfs_dir_create` and `hdfs_dir_remove` create and delete directories
* `hdfs_file_copy`, `hdfs_file_move`, `hdfs_file_rename` and `hdfs_file_remove` copy, move, rename and delete files
* `hdfs_expunge` empties the HDFS trash
* `in_hdfs` returns whether a dataset is in HDFS
* `local_exec` runs an expression in the local compute context


## Non-xdf and non-local data sources

Despite the name, dplyrXdf supports all file data sources defined by RevoScaleR, not just xdf files. This includes delimited text (`RxTextData`), SAS datasets (`RxSasData`) and SPSS datasets (`RxSpssData`). If you pass one of these data sources to a dplyrXdf pipeline, it will import the data to an xdf file first before executing the rest of the pipeline.

Most verbs will work transparently with datasets stored in both the native filesystem, and in HDFS (as when working with a Hadoop or Spark cluster). In general, the output of a verb will be created in the same filesystem as the input. To transfer data between the two filesystems, you can use `copy_to` to upload, and `as_data_frame`, `collect` and `compute` to download.

Similarly, all verbs will work transparently with both standard and _composite_ Xdf files. A composite Xdf is actually a directory that contains multiple data and metadata files. Xdf files in the native filesystem can be either standard or composite, but those in HDFS must be composite to work properly.


## Conclusion

This article has been a quick executive-summary introduction to dplyrXdf. If you have any suggestions on features to add (including bits of dplyr that have been left out) or bugs that need fixing, please [file an issue on the repo](https://github.com/RevolutionAnalytics/dplyrXdf/issues), or contact me at [hongooi@microsoft.com](hongooi@microsoft.com).

```{r echo=FALSE, message=FALSE, results="hide"}
unlink(c("airports.xdf", "flights.xdf", "flights_rx1.xdf", "flights_rx2.xdf", "flights_rx3.xdf"))
clean_dplyrxdf_dir("native")
```



