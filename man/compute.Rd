% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compute.R
\name{collect.RxXdfData}
\alias{collect.RxXdfData}
\alias{collect,}
\alias{compute}
\alias{compute.RxXdfData}
\alias{compute.RxDataSource}
\alias{collect.RxDataSource}
\title{Download a dataset to the local machine}
\usage{
\method{collect}{RxXdfData}(x, as_data_frame = TRUE, ...)

\method{compute}{RxXdfData}(x, as_data_frame = !in_hdfs(x), ...)

\method{compute}{RxDataSource}(x, name = NULL, ...)

\method{collect}{RxDataSource}(x, ...)
}
\arguments{
\item{x}{An Xdf data source object.}

\item{as_data_frame}{For the \code{RxXdfData} methods: should the downloaded data be converted to a data frame, or left as an Xdf file?}

\item{...}{If the output is to be a data frame, further arguments to the \code{as.data.frame} method.}

\item{name}{For the \code{RxDataSource} methods: the name of the Xdf file to create. Defaults to a temporary filename in the dplyrXdf working directory.}
}
\value{
For the \code{RxDataSource} methods, \code{collect} returns a data frame, and \code{compute} returns a tbl_xdf data source. For the \code{RxXdfData} methods, either a data frame or tbl_xdf based on the \code{as_data_frame} argument.
}
\description{
Download a dataset to the local machine
}
\details{
RevoScaleR does not have an exact analogue of the dplyr concept of a src, and because of this, the dplyrXdf implementations of \code{collect} and \code{compute} are somewhat different. In dplyrXdf, these functions serve two related, overlapping purposes:
\itemize{
   \item Copy an arbitrary data source from a backend to an Xdf file or data frame. The data source can be any (non-Xdf) RevoScaleR data source, such as a SQL Server table (class \code{RxSqlServerData}).
   \item Download an Xdf file from a remote filesystem, such as the HDFS filesystem of a Hadoop or Spark cluster.
}

The code will handle both the cases where you are logged into the edge node of a Hadoop/Spark cluster, and if you are a remote client. For the latter case, the downloading is a two-stage process: the data is first transferred from HDFS to the native filesystem of the edge node, and then downloaded from the edge node to the client.

If you want to look at the first few rows of an Xdf file in HDFS, it may be faster to use \code{compute}) to copy the entire file to the native filesystem, and then run \code{head}, than to run \code{head} on the original. This is due to quirks in how RevoScaleR works in Spark and Hadoop.
}
\examples{
mtx <- as_xdf(mtcars, overwrite=TRUE)

# all of these return a data frame (or a tbl_df) for input in the native filesystem
as.data.frame(mtx)
as_data_frame(mtx)  # returns a tbl_df
collect(mtx)
compute(mtx)

# collect and compute are meant for downloading data from remote backends
\dontrun{
# downloading from a database
connStr <- "SERVER=hostname;DATABASE=RevoTestDB;TRUSTED_CONNECTION=yes"
mtdb <- RxSqlServerData("mtcars", connectionString=connStr)
copy_to(mtdb, mtcars)
as.data.frame(mtdb)
collect(mtdb)  # returns a data frame
compute(mtdb)  # returns a tbl_xdf

# downloading from HDFS
mtc <- copy_to_hdfs(mtcars)
as.data.frame(mtc)
collect(mtc)  # returns a data frame
compute(mtc)  # returns a tbl_xdf
}
}
\seealso{
\code{\link{as_xdf}}, \code{\link{as_data_frame}}, \code{\link{copy_to}}, \code{\link[dplyr]{compute}} in package dplyr
}
