---
title: "Using the dplyrXdf package"
author: "Hong Ooi"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Using dplyrXdf}
  \usepackage[utf8]{inputenc}
---

```{r, echo = FALSE, message = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
options(dplyr.print_min = 5L, dplyr.print_max = 5L)
library(dplyrXdf)
```

This vignette goes into more details on using dplyrXdf. Most of dplyrXdf works the same way as dplyr, so if you know how to use the latter, then you also (mostly) know how to use the former. However, there are some places in which the two packages are different. These will be described below.

As with the introductory vignette, we'll use the nycflights13 flights data to demonstrate the use of dplyrXdf.

```{r}
library(dplyrXdf)  # also loads dplyr
library(nycflights13)

# write the data as an xdf file
flightsXdf <- rxDataStep(flights, "flights.xdf", overwrite=TRUE)
```


## Tbls and file management

To facilitate the task of file management, dplyrXdf defines a new `tbl_xdf` class that extends the `RxXdfData` class. This is what allows it to keep track of which data sources should remain untouched, and which can be modified or overwritten as part of a pipeline. To the base RevoScaleR functions, an `tbl_xdf` object is just a normal xdf data source; thus, existing code dealing with xdfs should work with minimal modification. However, the verbs implemented in dplyrXdf will recognise when they are passed a `tbl_xdf`, as opposed to a normal xdf file, in which case they will delete their input file after writing the output file. Thus there is always only one file that represents the latest stage of a pipeline.

To create a `tbl_xdf` yourself, you can call the `tbl` function on an xdf data source:

```{r}
flightsTbl <- tbl(flightsXdf)
flightsTbl
```

However this should rarely (if ever) be necessary, as dplyrXdf will automatically handle such matters.

A side-effect of dplyrXdf managing files for you is that you should be careful when passing the result from an initial pipeline into subsequent pipelines. Consider the following example:

```{r, eval=FALSE}
# pipeline 1
output1 <- flightsXdf %>%
    mutate(delay=(arr_delay + dep_delay)/2)

# use the output from pipeline 1
output2 <- output1 %>%
    group_by(carrier) %>%
    summarise(delay=mean(delay))

# reuse the output from pipeline 1 -- WRONG
output3 <- output1 %>%
    group_by(dest) %>%
    summarise(delay=mean(delay))
```

The bug in this code is that the second pipeline will overwrite or delete its input, so the third pipeline will fail. This is consistent with dplyrXdf's philosophy of only saving the most recent output of a pipeline, where a pipeline is defined as _all operations starting from a raw xdf file._ However, in this case it isn't what we want.

Similarly, dplyrXdf creates its output files in a temporary directory, which will be deleted when you quit R. This saves you having to manually delete files that are no longer in use, but it does mean that you must copy the results of your analyses to a permanent location if you want to keep it around.

dplyrXdf gives you two ways to deal with these issues.

### Specifying the output format

First, all dplyrXdf verbs support a special argument `.output`, which controls how the output data is handled. If you don't specify a value for this argument, the data will be saved to a `tbl_xdf` which will be managed by dplyrXdf. This supports the default behaviour of dplyrXdf, whereby data files are automatically created and deleted inside a pipeline. There are two other options for `.output`:

- If you specify `.output = NULL`, the data will be returned in memory as a data frame.

- If `.output` is a character string giving a file name, the data will be saved to an xdf file at that location, and a persistent xdf data source will be returned.

To show how this works, we can modify pipeline 1 above to save its output to a persistent location. This resets the status of the pipeline, so that subsequent operations will know not to modify the data.

```{r, eval=FALSE}
# pipeline 1 -- use .output to save the data
output1 <- flightsXdf %>%
    mutate(delay=(arr_delay + dep_delay)/2, .output="output1.xdf")

# use the output from pipeline 1
output2 <- output1 %>%
    group_by(carrier) %>%
    summarise(delay=mean(delay))

# reuse the output from pipeline 1 -- this works as expected
output3 <- output1 %>%
    group_by(dest) %>%
    summarise(delay=mean(delay))
```

### The `persist` verb

The second way of creating a persistent xdf file is with the `persist` verb. This is a simple function that moves or copies its input to the specified location. Like the `.output` argument described above, it will also reset the status of the pipeline.

```{r, eval=FALSE}
# pipeline 1 -- use persist to save the data
output1 <- flightsXdf %>%
    mutate(delay=(arr_delay + dep_delay)/2) %>% persist("output1_persist.xdf")

# use the output from pipeline 1
output2 <- output1 %>%
    group_by(carrier) %>%
    summarise(delay=mean(delay))

# reuse the output from pipeline 1 -- this also works as expected
output3 <- output1 %>%
    group_by(dest) %>%
    summarise(delay=mean(delay))
```

In general, setting `.output` to save an xdf file is preferred to using the `persist` verb. You would use `persist` if you have already run a pipeline, and want to save its output after the fact.


## The `subset` verb

In dplyr, subsetting data is handled by two verbs: `filter` for subsetting by rows, and `select` for subsetting by columns. This is fine for data frames, where everything runs in memory, and for SQL databases, where the hard work is done by the database. For xdf files, however, this is suboptimal, as each verb translates into a separate I/O step where the data is read from disk, subsetted, then written out again. This can waste a lot of time with large datasets.

As it turns out, base R has a `subset` generic which (as the name says) performs subsetting on both rows and columns. You've probably used it with data frames:

```{r}
subset(flights, month <= 6 & day == 1, c(dep_time, dep_delay, carrier))
```

dplyrXdf implements a method for `subset` that works for xdf files. The code is exactly the same as for a data frame, except that it creates another xdf file. This produces the same result as a `filter` followed by a `select`, but requires only half the amount of I/O.

```{r}
flightsXdfSub <- subset(flightsXdf, month <= 6 & day == 1, c(dep_time, dep_delay, carrier))
class(flightsXdfSub)
head(flightsXdfSub)
```


## The `.rxArgs` parameter

The RevoScaleR functions typically have several arguments beyond those used by dplyrXdf verbs. While usually you don't need to touch these, it can sometimes be useful to do so. For example, when using `mutate` or `transmute`, you could specify [more complicated transformations via a `transformFunc`](https://msdn.microsoft.com/en-us/microsoft-r/scaler/rxtransform). Similarly, rather than chaining together a `mutate` and a `summarise` --- which would involve creating an intermediate file --- you could incorporate the variable transformation into the `summarise` itself. More low-level uses of such arguments include setting the block size for an xdf file, changing the compression level, limiting the number of rows, and so on.

Most of the one-table dplyrXdf verbs accept an `.rxArgs` argument as a way of transmitting these extra arguments to the underlying RevoScaleR code. This should be a named list specifying the names and values of the arguments to be passed. The exact arguments will vary depending on the verb in question; here is a list of the verbs and the underlying RevoScaleR function that they call:

* `subset`, `filter` and `select`: `rxDataStep`
* `mutate` and `transmute`: `rxDataStep`
* `summarise`: depending on the method chosen, `rxCube` or `rxSummary`
* `arrange`: `rxSort`
* `distinct`: `rxDataStep`
* `factorise`: depending on the data source, `rxFactors` (for an xdf) or `rxImport` (for a non-xdf file source)
* `doXdf`: `rxDataStep`
* Two-table verbs (`left_join`, `right_join` et al): `rxMerge`

Here are some examples to illustrate the use of `.rxArgs`:

```{r}
# subset, transform and summarise in the one step
flightsSubsetSmry <- flightsXdf %>% group_by(day) %>%
    summarise(delay=mean(delay), n=n(),
        .rxArgs=list(
            transforms=list(delay=(dep_delay + arr_delay)/2),
            rowSelection=carrier == "UA"
        )
    )
head(flightsSubsetSmry)

# a complex transformation involving a transformFunc
flightsTrans <- transmute(flightsXdf, 
    .rxArgs=list(
        transformFunc=function(varlist) with(varlist, {
            delay <- (dep_delay + arr_delay)/2
            date <- as.Date(sprintf("%d-%02d-%02d", year, month, day))
            weekday <- weekdays(date)
            weekendDelay <- ifelse(weekday %in% c("Saturday", "Sunday"),
                                   delay, NA)
            list(delay=delay, weekday=weekday, weekendDelay=weekendDelay)
        })
    )
)
head(flightsTrans)

# fit a model using open source R, and then score the training dataset
# we pass the model object via transformObjects, and the package to load
# via transformPackages
library(rpart)
flightsModel <- rpart(arr_delay ~ dep_delay + carrier + hour, data=flights)

flightsScores <- transmute(flightsXdf,
    pred=predict(model, data.frame(dep_delay, carrier, hour)),
    .rxArgs=list(
        transformObjects=list(model=flightsModel),
        transformPackages="rpart"
    )
)
head(flightsScores)
```

You should use `.rxArgs` with caution, as some verbs modify the data as part of their normal functioning, so the results you get back may not be as expected. It's also easy to write convoluted code that makes your dplyrXdf pipelines harder to read. Nevertheless, if you are working with very large datasets and speed is important, this is one way to improve the efficiency of your code.


## Setting the summary method for `summarise`

For best performance, when using `summarise` you should request only those summary statistics supported by `rxCube` and/or `rxSummary`: sum, mean, min, max, sd, var and n (the count of observations). If you request something else, dplyrXdf will split the dataset into multiple data frames, one per group, and call `dplyr::summarise` on each data frame; this will generally work as intended, but may be slow.

The dplyrXdf version of `summarise` can choose from a number of methods for computing the summary statistics. While it's usually smart enough to choose the best method, you can set this manually with the `.method` argument, which takes a number from 1 to 5:

1. Use `rxCube`
2. Use `rxSummary`
3. Use `rxSummary` but create the groups by concatenating the grouping variables together; this is to work around a limitation in the RevoScaleR functions on the maximum number of cells in a cube
4. Split the dataset into multiple data frames, call `dplyr::summarise` on each
5. Split the dataset into multiple xdf files, call `rxSummary` on each

Only methods 1, 2 and 3 support the use of `.rxArgs`.

In addition, dplyrXdf `summarise` doesn't support expressions as summary statistics. For example, something like `summarise(datasrc, weightedMean=sum(x*wt)/sum(wt))` works when `datasrc` is a data frame, but not when it is an xdf. To get the desired result, one workaround would be to use three verbs in a pipeline:

```{r, eval=FALSE}
datasrc %>%
    mutate(xwt=sum(x*wt)) %>%
    summarise(xwt=sum(xwt), wt=sum(wt)) %>%
    mutate(weightedMean=xwt/wt)
```

In this particular case though, you could also use `rxCube`'s built-in `pweight` argument to compute the weighted mean:

```{r, eval=FALSE}
datasrc %>%
    summarise(weightedMean=mean(x), .rxArgs=list(pweight="wt"))
```


## Creating factors with `factorise`

Many RevoScaleR functions are optimised to work best with factors, or require factors as input. dplyrXdf provides a simple shell to the `rxFactors` function to convert non-factor variables to factors. The syntax is as follows:

```{r, eval=FALSE}
factorise(data, x1, x2, ...)
```

where `x1`, `x2`, ... are the variables to convert. Note that the generated factor variables will overwrite the originals. For performance reasons, the levels of the generated factors are not sorted in alphabetical order. You can also specify the levels for the factor(s) in question, using the standard name=value syntax:

```{r, eval=FALSE}
factorise(data, x1=c("a", "b", "c"))
```

This will convert the variable `x1` into a factor with levels `a`, `b` and `c`. Any values that don't match the specified levels will be turned into NAs.

The verbs in dplyrXdf will usually create factors on the fly as needed, so you shouldn't need to call `factorise` very often. However, should you need it, `factorise` provides an explicit way to create factors within the framework of dplyrXdf and pipelines.

There are a number of ways to specify the variables to convert, in addition to naming them explicitly. The functions `all_character()`, `all_numeric()` and `all_integer()` will convert all the variables falling under these categories. A logical variable counts as integer for this purpose. You can also use the helper functions available to `dplyr::select_vars` to choose variables based on their names.

By default, if no variables are specified in the `factorise` call, then all character variables will be converted to factors. As with `select`, renaming variables as part of the factor conversion is not supported.


## Executing code with `do` and `doXdf`

The `do` verb is an exception to the rule that `dplyrXdf` verbs write their output as xdf files. This is because `do` executes arbitrary R code, and can return arbitrary R objects; while a data frame is capable of storing these objects, an xdf file is limited to character and numeric vectors only.

The `doXdf` verb is similar to `do`, but where `do` splits its input into one data frame per group, `doXdf` splits it into one xdf file per group. This allows `do`-like functionality with grouped data, where each group can be arbitrarily large. The syntax for the two functions is essentially the same, although the code passed to `doXdf` must obviously know how to handle xdfs.

```{r}
# fit a regression model by carrier, using rxLinMod
flightsMods <- flightsXdf %>%
    group_by(carrier) %>%
    doXdf(model=rxLinMod(arr_delay ~ dep_delay + hour, data=.))

flightsMods$model[[1]]
```


## Setting the tbl directory

By default, dplyrXdf will save the files it creates into the R working directory. On some systems, this may be located on a filesystem that is relatively small; this is rarely an issue with open source R, as all its objects are loaded into memory, but can be problematic with large xdf files. You can view the location of the current xdf tbl directory with `getXdfTblDir`:

```{r}
getXdfTblDir()
```

Similarly, you can change the location of the xdf tbl directory with the `setXdfTblDir` function:

```{r, eval=FALSE}
# set the tbl directory to a network drive (on Windows)
setXdfTblDir("n:/Rtemp")
```

## Data frame methods

dplyrXdf includes a number of convenience functions for exporting data from xdf to data frames:

- An `as.data.frame` method for xdf files (and other RevoScaleR data sources).
- Methods for `$` and `[[` that will extract a given column as a vector in memory.

These are simple wrappers around RevoScaleR's `rxDataStep` function that turn off the default size check. Make sure you have enough memory to hold the data before using them!

